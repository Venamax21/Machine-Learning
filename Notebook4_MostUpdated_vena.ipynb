{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j23-cs167/notebook-4-Venamax21/blob/main/Notebook4_MostUpdated_vena.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G04Rsb8TOYv1"
      },
      "source": [
        "# Notebook \\#4\n",
        "\n",
        "**Part 1: [3 points]** You must run at least 6 variations of the algorithms and display their results using an __appropriate regression metric__ (again, use the scikit-learn modules). I will be looking for the following to be included in your comparison:\n",
        "\n",
        "* **weighted k-Nearest-Neighbor** with a **small value of k** (the same one you used for the unweighted version)\n",
        "* **weighted k-Nearest-Neighbor** with a **large value of k **(the same one you used for the unweighted version)\n",
        "* a **decision tree** with default parameter values\n",
        "* a **decision tree**, setting some kind of parameter that results in a smaller tree \n",
        "* a **Random Forest**, with default parameter values\n",
        "* a **Random Forest**, with a **change to the number of trees** used.\n",
        "\n",
        "You will need to use the documentation for sklearn for this Notebook. Here are some helpful links:\n",
        "* [K Neighbors Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)\n",
        "* [Decision Tree Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MFqxiHDBlEeq",
        "outputId": "0f71c1e3-db7f-4689-a466-c3dc37e111c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWJ8-XD8OzPx"
      },
      "source": [
        "# load in the data and necessary libraries\n",
        "import sklearn\n",
        "import numpy \n",
        "import pandas \n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import neighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import ensemble\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "songs = pandas.read_csv('/content/drive/MyDrive/ColabNotebooks/CS167Datasets/spotify.csv') # change this to match your dataset directory\n",
        "songs.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exaUcSQxI5FU"
      },
      "source": [
        "\n",
        "# Split the data into the training data and testing data\n",
        "# we're only going to use a subset of the columns that are numeric\n",
        "target= 'danceability'\n",
        "predictors = ['energy', 'key', 'loudness','speechiness','acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo','duration_ms']\n",
        "train_data, test_data, train_sln, test_sln = train_test_split(songs[predictors], songs[target], test_size = 0.2, random_state=41)\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "songs.isnull().sum()"
      ],
      "metadata": {
        "id": "Fcpjpa3J2d2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# w-kNN with small k\n",
        "\n",
        "#3. Create your Model\n",
        "small_weighted_knn = neighbors.KNeighborsRegressor(weights = 'distance') #default k = 5\n",
        "\n",
        "#4. Call fit() to train model\n",
        "small_weighted_knn.fit(train_data, train_sln)\n",
        "\n",
        "#5. Get predictions using predict()\n",
        "small_weightedKNN_predictions = small_weighted_knn.predict(test_data)\n",
        "\n",
        "#6. Evaluate the Model\n",
        "print(\"Small-K Weighted KNN MSE: \", metrics.mean_squared_error(small_weightedKNN_predictions, test_sln))"
      ],
      "metadata": {
        "id": "w9nx8E_tP1F_",
        "outputId": "7473ca12-0686-4c66-e2ea-b9419c1f9401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small-K Weighted KNN MSE:  0.020534714145327582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# w-kNN with large K \n",
        "\n",
        "#3. Create your Model\n",
        "large_weighted_knn = neighbors.KNeighborsRegressor(n_neighbors = 40, weights = 'distance') #large value k=40\n",
        "\n",
        "#4. Call fit() to train model\n",
        "large_weighted_knn.fit(train_data, train_sln)\n",
        "\n",
        "#5. Get predictions using predict()\n",
        "large_weightedKNN_predictions = large_weighted_knn.predict(test_data)\n",
        "\n",
        "#6. Evaluate the Model\n",
        "print(\"Large-K Weighted KNN MSE: \", metrics.mean_squared_error(large_weightedKNN_predictions, test_sln))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFBEq0BKk03X",
        "outputId": "62de5e86-e5f8-4934-a387-d2d9d887c7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large-K Weighted KNN MSE:  0.017259565241725186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree default parameter values\n",
        "\n",
        "#3. Create your model\n",
        "small_dt = tree.DecisionTreeRegressor()\n",
        "\n",
        "#4. Call fit() to train your model\n",
        "small_dt.fit(train_data, train_sln)\n",
        "\n",
        "#5. Get Predictions using predict()\n",
        "small_dt_predictions = small_dt.predict(test_data)\n",
        "\n",
        "#6. Evaluate the model\n",
        "print(\"Decision Tree MSE: \", metrics.mean_squared_error(small_dt_predictions, test_sln))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F9nKkFEFy8-",
        "outputId": "c427507a-4d26-44ba-bddf-2ef392d30f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree MSE:  0.017123991739747078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree with some kind of parameter that (hopefully) results in a smaller tree\n",
        "\n",
        "#3. Create your model\n",
        "smaller_dt = tree.DecisionTreeRegressor(max_depth = 9) #max_depth to 9\n",
        "\n",
        "#4. Call fit() to train your model\n",
        "smaller_dt.fit(train_data, train_sln)\n",
        "\n",
        "#5. Get Predictions using predict()\n",
        "smaller_dt_predictions = smaller_dt.predict(test_data)\n",
        "\n",
        "#6. Evaluate the model\n",
        "print(\"Smaller Tree Decision Tree MSE: \", metrics.mean_squared_error(smaller_dt_predictions, test_sln))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv7cdatTQ1QD",
        "outputId": "d59e5e17-2bf5-47e1-cd98-652a02d1e306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smaller Tree Decision Tree MSE:  0.013154873613332911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5kncBKlOrhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be5138f-b050-45e3-d338-ab3be91e81b8"
      },
      "source": [
        "# Random Forest with a small number of trees\n",
        "\n",
        "#3. Create your model\n",
        "small_forest = RandomForestRegressor() #default value is 100 trees\n",
        "\n",
        "#4. Call fit() to train your model\n",
        "small_forest.fit(train_data, train_sln)\n",
        "\n",
        "#5. Get Predictions using predict()\n",
        "small_forest_predictions = small_forest.predict(test_data)\n",
        "\n",
        "#6. Evaluate the model\n",
        "print(\"Random Small Forest MSE: \", metrics.mean_squared_error(small_forest_predictions, test_sln))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Small Forest MSE:  0.008632824691790213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest with a large number of trees\n",
        "\n",
        "#3. Create your model\n",
        "large_forest = RandomForestRegressor(n_estimators= 400) #The number of trees increased to 400 \n",
        "\n",
        "#4. Call fit() to train your model\n",
        "large_forest.fit(train_data, train_sln)\n",
        "\n",
        "#5. Get Predictions using predict()\n",
        "large_forest_predictions = large_forest.predict(test_data)\n",
        "\n",
        "#6. Evaluate the model\n",
        "print(\"Random Large Forest MSE: \", metrics.mean_squared_error(large_forest_predictions, test_sln))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDh-2F7lSLS6",
        "outputId": "d02654c0-d268-4ef7-ec22-6ee1b574d977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Large Forest MSE:  0.008559818456948587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_1BW2sPPNro"
      },
      "source": [
        "## Part 2: w-kNN on Normalized data\n",
        "**2.)** Normalize the data and run a weighted k-Nearest Neighbors algorithm on it (from sklearn,  not the one we wrote from scratch). You can choose the k value. To Normalize, use the StandardScalar from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train_data)\n",
        "train_data_normalized = scaler.transform(train_data)\n",
        "test_data_normalized = scaler.transform(test_data)"
      ],
      "metadata": {
        "id": "E6tldEIMSpDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NORMALIZED W-kNN with large K\n",
        "#3. Create your model \n",
        "norm_small_weighted_knn = neighbors.KNeighborsRegressor(n_neighbors = 40, weights = 'distance') #large k = 40\n",
        "\n",
        "#4. Call fit() to train your model\n",
        "norm_small_weighted_knn.fit(train_data_normalized, train_sln)\n",
        "\n",
        "#5. Get Predictions using predict()\n",
        "norm_weighted_predictions = norm_small_weighted_knn.predict(test_data_normalized)\n",
        "\n",
        "#6. Evaluate the model\n",
        "print(\"Normalized weighted KNN MSE: \", metrics.mean_squared_error(norm_weighted_predictions, test_sln))"
      ],
      "metadata": {
        "id": "U5hRlpycSr8N",
        "outputId": "a422ac00-3ae5-4cce-e0fb-a82cfe746dd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized weighted KNN MSE:  0.009636577577788205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28SLxo80PckN"
      },
      "source": [
        "## Part 3:\n",
        "**3.)**Use a Markup cell to answer the following questions:\n",
        "* What algorithm performed better? w-kNN, Decision Trees, or Random Forests? Why do you think this was the case?\n",
        "* What effect did normalizing the data have on your results? Explain. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest algorithm \"with a large number of trees\" performed the best with an MSE of 0.0085. I increased the number of trees to 400 and my model was able to become the best model. It was very close to the other Random forest with small number of trees with 0.0086 MSE which has 100 trees. Random forest performed the best because it's an advanced version of Decision tree, which also came out with a very small MSE of 0.013, setting max depth at 9. Although Random forest performed the best with more trees (n_estimator = 400), the model was so much slower. It took more than 30 seconds to run it. \n",
        "\n",
        "Normalizing data brought a significant change and it had a much greater performance on my model. Normalized kNN with a large k-value of 40 gives me an MSE of 0.0096, just slightly behind Random forest models. The weighted kNN with a default value k=5 performance was 0.0205 whereas the large value k=40 performance was better at 0.0172 MSE. "
      ],
      "metadata": {
        "id": "9v6nG1e9veHT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JAiL7X_iYeu6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}